{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9531342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Average       1.00      1.00      1.00       275\n",
      "        Best       1.00      1.00      1.00       172\n",
      "        Poor       1.00      1.00      1.00       553\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the modified dataset\n",
    "df = pd.read_csv('credit_score_data_modified.csv')\n",
    "\n",
    "# Prepare features and target variable\n",
    "X = df.drop(columns=['Credit_Score_Category'])\n",
    "y = df['Credit_Score_Category']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define column transformers for numerical and categorical columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with preprocessing steps and model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the model for future use\n",
    "# (e.g., using joblib: https://scikit-learn.org/stable/modules/model_persistence.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad4224df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 6237.9245957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['credit_score_prediction_model.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the modified dataset\n",
    "df = pd.read_csv('credit_score_data_modified.csv')\n",
    "\n",
    "# Prepare features and target variable\n",
    "X = df.drop(columns=['Credit_Score','Credit_Score_Category'])\n",
    "y = df['Credit_Score']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define column transformers for numerical and categorical columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with preprocessing steps and model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# input()\n",
    "\n",
    "# Save the trained model\n",
    "import joblib\n",
    "joblib.dump(pipeline, 'credit_score_prediction_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "959b2adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fake = pipeline.predict(X.iloc[[652]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78cbec38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([557.04])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42e88a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Dependents_Count</th>\n",
       "      <th>Livestock_Presence</th>\n",
       "      <th>Personal_Vehicle_Presence</th>\n",
       "      <th>Owns_House</th>\n",
       "      <th>Owns_Farm</th>\n",
       "      <th>Farm_Size_Acres</th>\n",
       "      <th>Irrigation_Presence</th>\n",
       "      <th>...</th>\n",
       "      <th>Yield_2Years_Ago_Tons</th>\n",
       "      <th>Investment_2Years_Ago</th>\n",
       "      <th>Profit_2Years_Ago</th>\n",
       "      <th>Yield_1Year_Ago_Tons</th>\n",
       "      <th>Investment_1Year_Ago</th>\n",
       "      <th>Profit_1Year_Ago</th>\n",
       "      <th>Market_Trend</th>\n",
       "      <th>Crop_Name</th>\n",
       "      <th>Credit_Score</th>\n",
       "      <th>Credit_Score_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57</td>\n",
       "      <td>False</td>\n",
       "      <td>Primary School</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4.36</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>17.48</td>\n",
       "      <td>1077</td>\n",
       "      <td>1333</td>\n",
       "      <td>36.17</td>\n",
       "      <td>5674</td>\n",
       "      <td>2465</td>\n",
       "      <td>Growing</td>\n",
       "      <td>Rice</td>\n",
       "      <td>611</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "      <td>Primary School</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5.23</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>19.22</td>\n",
       "      <td>2371</td>\n",
       "      <td>1601</td>\n",
       "      <td>50.01</td>\n",
       "      <td>3167</td>\n",
       "      <td>2654</td>\n",
       "      <td>Declining</td>\n",
       "      <td>Soybean</td>\n",
       "      <td>489</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>True</td>\n",
       "      <td>Primary School</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5.92</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>46.63</td>\n",
       "      <td>3172</td>\n",
       "      <td>874</td>\n",
       "      <td>26.28</td>\n",
       "      <td>4153</td>\n",
       "      <td>2307</td>\n",
       "      <td>Declining</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>304</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "      <td>Master</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>43.50</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>96.28</td>\n",
       "      <td>8856</td>\n",
       "      <td>3213</td>\n",
       "      <td>71.09</td>\n",
       "      <td>6503</td>\n",
       "      <td>5551</td>\n",
       "      <td>Declining</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>831</td>\n",
       "      <td>Best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "      <td>Primary School</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>7.95</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>14.89</td>\n",
       "      <td>1240</td>\n",
       "      <td>1066</td>\n",
       "      <td>28.92</td>\n",
       "      <td>2178</td>\n",
       "      <td>2044</td>\n",
       "      <td>Stable</td>\n",
       "      <td>Rice</td>\n",
       "      <td>456</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "      <td>Secondary School</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7.44</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>12.16</td>\n",
       "      <td>2854</td>\n",
       "      <td>1670</td>\n",
       "      <td>38.65</td>\n",
       "      <td>3051</td>\n",
       "      <td>1480</td>\n",
       "      <td>Growing</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>529</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>39</td>\n",
       "      <td>True</td>\n",
       "      <td>Master</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>20.50</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>56.22</td>\n",
       "      <td>5680</td>\n",
       "      <td>4184</td>\n",
       "      <td>95.39</td>\n",
       "      <td>9535</td>\n",
       "      <td>5625</td>\n",
       "      <td>Growing</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>899</td>\n",
       "      <td>Best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>45</td>\n",
       "      <td>False</td>\n",
       "      <td>Primary School</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.02</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>10.85</td>\n",
       "      <td>2355</td>\n",
       "      <td>1418</td>\n",
       "      <td>22.73</td>\n",
       "      <td>3213</td>\n",
       "      <td>1727</td>\n",
       "      <td>Growing</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>632</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>51</td>\n",
       "      <td>False</td>\n",
       "      <td>Postgraduate</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10.01</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>46.97</td>\n",
       "      <td>3399</td>\n",
       "      <td>3966</td>\n",
       "      <td>42.71</td>\n",
       "      <td>6926</td>\n",
       "      <td>2022</td>\n",
       "      <td>Stable</td>\n",
       "      <td>Corn</td>\n",
       "      <td>750</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>53</td>\n",
       "      <td>True</td>\n",
       "      <td>Primary School</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6.53</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>24.56</td>\n",
       "      <td>3287</td>\n",
       "      <td>1046</td>\n",
       "      <td>22.86</td>\n",
       "      <td>5980</td>\n",
       "      <td>2789</td>\n",
       "      <td>Stable</td>\n",
       "      <td>Corn</td>\n",
       "      <td>520</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Marital_Status   Education_Level  Dependents_Count  \\\n",
       "0      57           False    Primary School                 5   \n",
       "1      22           False    Primary School                 2   \n",
       "2      48            True    Primary School                 1   \n",
       "3      28           False            Master                 3   \n",
       "4      26            True    Primary School                 6   \n",
       "...   ...             ...               ...               ...   \n",
       "4995   28           False  Secondary School                10   \n",
       "4996   39            True            Master                 0   \n",
       "4997   45           False    Primary School                 3   \n",
       "4998   51           False      Postgraduate                 1   \n",
       "4999   53            True    Primary School                 8   \n",
       "\n",
       "      Livestock_Presence  Personal_Vehicle_Presence  Owns_House  Owns_Farm  \\\n",
       "0                   True                      False        True       True   \n",
       "1                  False                       True        True       True   \n",
       "2                  False                       True        True       True   \n",
       "3                   True                       True        True       True   \n",
       "4                   True                      False        True       True   \n",
       "...                  ...                        ...         ...        ...   \n",
       "4995               False                      False       False       True   \n",
       "4996               False                       True        True       True   \n",
       "4997                True                      False       False      False   \n",
       "4998               False                      False        True      False   \n",
       "4999               False                      False        True      False   \n",
       "\n",
       "      Farm_Size_Acres  Irrigation_Presence  ... Yield_2Years_Ago_Tons  \\\n",
       "0                4.36                 True  ...                 17.48   \n",
       "1                5.23                False  ...                 19.22   \n",
       "2                5.92                 True  ...                 46.63   \n",
       "3               43.50                 True  ...                 96.28   \n",
       "4                7.95                False  ...                 14.89   \n",
       "...               ...                  ...  ...                   ...   \n",
       "4995             7.44                False  ...                 12.16   \n",
       "4996            20.50                 True  ...                 56.22   \n",
       "4997             1.02                False  ...                 10.85   \n",
       "4998            10.01                False  ...                 46.97   \n",
       "4999             6.53                 True  ...                 24.56   \n",
       "\n",
       "     Investment_2Years_Ago  Profit_2Years_Ago  Yield_1Year_Ago_Tons  \\\n",
       "0                     1077               1333                 36.17   \n",
       "1                     2371               1601                 50.01   \n",
       "2                     3172                874                 26.28   \n",
       "3                     8856               3213                 71.09   \n",
       "4                     1240               1066                 28.92   \n",
       "...                    ...                ...                   ...   \n",
       "4995                  2854               1670                 38.65   \n",
       "4996                  5680               4184                 95.39   \n",
       "4997                  2355               1418                 22.73   \n",
       "4998                  3399               3966                 42.71   \n",
       "4999                  3287               1046                 22.86   \n",
       "\n",
       "      Investment_1Year_Ago  Profit_1Year_Ago  Market_Trend  Crop_Name  \\\n",
       "0                     5674              2465       Growing       Rice   \n",
       "1                     3167              2654     Declining    Soybean   \n",
       "2                     4153              2307     Declining      Wheat   \n",
       "3                     6503              5551     Declining      Wheat   \n",
       "4                     2178              2044        Stable       Rice   \n",
       "...                    ...               ...           ...        ...   \n",
       "4995                  3051              1480       Growing      Wheat   \n",
       "4996                  9535              5625       Growing      Wheat   \n",
       "4997                  3213              1727       Growing      Wheat   \n",
       "4998                  6926              2022        Stable       Corn   \n",
       "4999                  5980              2789        Stable       Corn   \n",
       "\n",
       "     Credit_Score Credit_Score_Category  \n",
       "0             611                  Poor  \n",
       "1             489                  Poor  \n",
       "2             304                  Poor  \n",
       "3             831                  Best  \n",
       "4             456                  Poor  \n",
       "...           ...                   ...  \n",
       "4995          529                  Poor  \n",
       "4996          899                  Best  \n",
       "4997          632                  Poor  \n",
       "4998          750               Average  \n",
       "4999          520                  Poor  \n",
       "\n",
       "[5000 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a9bef92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 6131.6439538690465\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_credit_score_prediction_model.joblib']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the modified dataset\n",
    "df = pd.read_csv('credit_score_data_modified.csv')\n",
    "\n",
    "# Prepare features and target variable\n",
    "X = df.drop(columns=['Credit_Score','Credit_Score_Category'])\n",
    "y = df['Credit_Score']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define column transformers for numerical and categorical columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with preprocessing steps and model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Define hyperparameters grid for tuning\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__max_depth': [None, 10, 20],\n",
    "    'regressor__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "input()\n",
    "\n",
    "# Save the best model\n",
    "import joblib\n",
    "joblib.dump(best_model, 'best_credit_score_prediction_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2efa6b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 6309.908356469857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_gradient_boosting_model.joblib']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the modified dataset\n",
    "df = pd.read_csv('credit_score_data_modified.csv')\n",
    "\n",
    "# Prepare features and target variable\n",
    "X = df.drop(columns=['Credit_Score','Credit_Score_Category'])\n",
    "y = df['Credit_Score']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define column transformers for numerical and categorical columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with preprocessing steps and model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', GradientBoostingRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Define hyperparameters grid for tuning\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__learning_rate': [0.05, 0.1, 0.2],\n",
    "    'regressor__max_depth': [3, 4, 5],\n",
    "    'regressor__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Save the best model\n",
    "import joblib\n",
    "joblib.dump(best_model, 'best_gradient_boosting_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79b9506d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 7544.0699471526195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_svr_model.joblib']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the modified dataset\n",
    "df = pd.read_csv('credit_score_data_modified.csv')\n",
    "\n",
    "# Prepare features and target variable\n",
    "X = df.drop(columns=['Credit_Score','Credit_Score_Category'])\n",
    "y = df['Credit_Score']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define column transformers for numerical and categorical columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with preprocessing steps and model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', SVR())\n",
    "])\n",
    "\n",
    "# Define hyperparameters grid for tuning\n",
    "param_grid = {\n",
    "    'regressor__kernel': ['linear', 'poly', 'rbf'],\n",
    "    'regressor__C': [0.1, 1, 10],\n",
    "    'regressor__gamma': ['scale', 'auto'],\n",
    "    'regressor__epsilon': [0.1, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Save the best model\n",
    "import joblib\n",
    "joblib.dump(best_model, 'best_svr_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d0310c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 8700.613215903986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_ridge_model.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the modified dataset\n",
    "df = pd.read_csv('credit_score_data_modified.csv')\n",
    "\n",
    "# Prepare features and target variable\n",
    "X = df.drop(columns=['Credit_Score','Credit_Score_Category'])\n",
    "y = df['Credit_Score']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define column transformers for numerical and categorical columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with preprocessing steps and model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', Ridge())\n",
    "])\n",
    "\n",
    "# Define hyperparameters grid for tuning\n",
    "param_grid = {\n",
    "    'regressor__alpha': [0.1, 1, 10],\n",
    "    'regressor__solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Save the best model\n",
    "import joblib\n",
    "joblib.dump(best_model, 'best_ridge_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e7cb80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 8625.721113228117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_lasso_model.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the modified dataset\n",
    "df = pd.read_csv('credit_score_data_modified.csv')\n",
    "\n",
    "# Prepare features and target variable\n",
    "X = df.drop(columns=['Credit_Score','Credit_Score_Category'])\n",
    "y = df['Credit_Score']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define column transformers for numerical and categorical columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with preprocessing steps and model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', Lasso())\n",
    "])\n",
    "\n",
    "# Define hyperparameters grid for tuning\n",
    "param_grid = {\n",
    "    'regressor__alpha': [0.1, 1, 10],\n",
    "    'regressor__tol': [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Save the best model\n",
    "import joblib\n",
    "joblib.dump(best_model, 'best_lasso_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef608756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 8675.553907394566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_elasticnet_model.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the modified dataset\n",
    "df = pd.read_csv('credit_score_data_modified.csv')\n",
    "\n",
    "# Prepare features and target variable\n",
    "X = df.drop(columns=['Credit_Score','Credit_Score_Category'])\n",
    "y = df['Credit_Score']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define column transformers for numerical and categorical columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with preprocessing steps and model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', ElasticNet())\n",
    "])\n",
    "\n",
    "# Define hyperparameters grid for tuning\n",
    "param_grid = {\n",
    "    'regressor__alpha': [0.1, 1, 10],\n",
    "    'regressor__l1_ratio': [0.1, 0.5, 0.9],\n",
    "    'regressor__tol': [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Save the best model\n",
    "import joblib\n",
    "joblib.dump(best_model, 'best_elasticnet_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478913ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
